{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<span style=\"font-family:Comic Sans MS; color:navy\"><h2>Titanic Binary classfication</h2></span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"font-family:Comic Sans MS; color:navy\"><h5>1:About DataSet</h5></span>\n",
    "- <span style='font-family:comic Sans MS; color:navy'> Project Summary: The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.</span>\n",
    "\n",
    "- <span style='font-family:comic Sans MS; color:navy'>One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.</span>\n",
    "<div>\n",
    "    \n",
    "</div>\n",
    "<center>    \n",
    "<img src=\"https://t2.gstatic.com/licensed-image?q=tbn:ANd9GcScs1kCii2vJENMwTk2oDcUTmdYuuuWIa60xfevnMjHPbCMjIlb5Ssl23u7DoW_BRgc\", width=\"400\",  height=\"300\"/>\n",
    "</center>\n",
    "\n",
    "# <span style=\"font-family:Comic Sans MS; color:navy\"><h5>2: Define the Problem</h5></span>\n",
    "- <span style='font-family:comic Sans MS; color:navy'>In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy</span>\n",
    "<div>\n",
    "\n",
    "</div>\n",
    "<center>    \n",
    "<img src=\"https://www.titanicuniverse.com/wp-content/uploads/2022/08/how-many-people-survived-the-titanic-featured-930x620-1.jpg\", width=\"400\",  height=\"300\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family:Comic Sans MS; color:navy\"><h5>3:Import Libraries</h5></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "#ignore warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#for graphs, visuals, etc.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import plotly.express as px\n",
    "# import cufflinks as cf\n",
    "# cf.go_offline()\n",
    "\n",
    "# for Modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "# %matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "# pylab.rcParams['figure.figsize'] = 12,8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family:Comic Sans MS; color:navy\"><h5>4:Import Data</h5></span>\n",
    "- <span style='font-family:comic Sans MS; color:navy'>It's my first competation in Kaggle,Titanic DataSet have 3 part:\n",
    "    <ul>\n",
    "        <li>\n",
    "            <h6>train.csv:</h6> Contains the details of a subset of the passengers on board (891 passengers, to be exact -- where each passenger gets a different row in the table). To investigate this data, click on the name of the file on the left of the screen. Once you've done this, you can view all of the data in the window.\n",
    "        </li>\n",
    "        <li>\n",
    "            <h6>test.csv:</h6>\n",
    "            Using the patterns you find in train.csv, you have to predict whether the other 418 passengers on board (in test.csv) survived\n",
    "        </li>\n",
    "        <li>\n",
    "          <h6>gender_submission.csv:</h6>\n",
    "            The gender_submission.csv file is provided as an example that shows how you should structure your predictions\n",
    "        </li>\n",
    "    </ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-4e441f2240f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtod_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Data/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtod_gender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Data/gender_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtod_sum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtod_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "tod = pd.read_csv('./Data/train.csv')\n",
    "tod_test = pd.read_csv('./Data/test.csv')\n",
    "tod_gender = pd.read_csv('./Data/gender_submission.csv')\n",
    "tod_sum[tod,tod_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family:Comic Sans MS; color:navy\"><h5>5:PreProccessing</h5></span>\n",
    "## <span style=\"font-family:Comic Sans MS; color:navy\"><h5>5.1:How data look</h5></span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "tod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "tod_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_submission\n",
    "tod_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Comic Sans MS; color:navy\"><h5>5.2:Data information</h5></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns\n",
    "tod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tod.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Comic Sans MS; color:navy\"><h5>5.3:Data Cleaning</h5></span>\n",
    "### <span style=\"font-family:Comic Sans MS; color:navy\"><h5>5.3.1:Correcting</h5></span>\n",
    "- <span style='font-family:comic Sans MS; color:navy'>correcting aberrant values and outliers</span>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare outliers from train\n",
    "outliers_fare = tod['Fare'].max()\n",
    "tod['Fare'][tod['Fare']==outliers_fare]\n",
    "tod.drop([258,679,737],axis=0,inplace=True)\n",
    "# Fare outliers from test\n",
    "outliers_fare = tod_test['Fare'].max()\n",
    "tod_test['Fare'][tod_test['Fare']==outliers_fare]\n",
    "tod_test.drop(343,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SibSp outliers for train\n",
    "outliers_parch = tod['SibSp'].max()\n",
    "tod['SibSp'][tod['SibSp']==outliers_parch]\n",
    "tod.drop([159,180,201,324,792,846,863],axis=0,inplace=True)\n",
    "# SibSp outliers for test\n",
    "outliers_parch = tod_test['SibSp'].max()\n",
    "tod_test['SibSp'][tod_test['SibSp']==outliers_parch]\n",
    "tod.drop([188,360],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SibSp outliers for train\n",
    "outliers_parch = tod['Parch'].max()\n",
    "tod['Parch'][tod['Parch']==outliers_parch]\n",
    "tod.drop(678,axis=0,inplace=True)\n",
    "# SibSp outliers for test\n",
    "outliers_parch = tod_test['Parch'].max()\n",
    "tod_test['Parch'][tod_test['Parch']==outliers_parch]\n",
    "tod.drop([342,365],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family:Comic Sans MS; color:navy\"><h5>5.3.2:Completing</h5></span>\n",
    "- <span style='font-family:comic Sans MS; color:navy'>completing missing information</span>\n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train data with null:\\n',tod.isnull().sum())\n",
    "print('_--'*20)\n",
    "print('test data with null:\\n\\n',tod_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style='font-family:comic Sans MS; color:navy'>Now we fill or drop the columns:</span>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tod_sum:    \n",
    "    #complete with median\n",
    "    x['Age'].fillna(x['Age'].median(), inplace = True)\n",
    "\n",
    "    #complete with mode\n",
    "    x['Embarked'].fillna(x['Embarked'].mode()[0], inplace = True)\n",
    "\n",
    "    #complete median\n",
    "    x['Fare'].fillna(x['Fare'].median(), inplace = True)\n",
    "\n",
    "#delete the cabin feature/column and others previously stated to exclude in train dataset\n",
    "dropC = ['PassengerId','Cabin', 'Ticket']\n",
    "tod.drop(dropC, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
